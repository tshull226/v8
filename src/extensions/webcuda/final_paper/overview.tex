
%used for spell checking - works for some reason...
%(
\begin{table}
\begin{center}
\begin{tabular}{| l | p{5.5cm} | }
\hline
Function Name & Brief Description \\
\hline
Device & Retrieve Handle to CUDA-enabled device \\
\hline
Context & Setup CUDA context on specific device \\
\hline
ctxFree & Free resources consumed by specified CUDA context\\
\hline
memAlloc & Allocate CUDA device memory \\
\hline
copyHtoD  & Copy host memory to CUDA device \\
\hline
copyDtoH & Copy CUDA device memory to host \\
\hline
free & Free CUDA device Memory \\
\hline
compileFile & Compile and load specified .cu file \\
\hline
moduleLoad & Load specified .cubin or .ptx file \\
\hline
moduleUnload & Free resources consumed by specified CUDA module\\
\hline
launchKernel & Launch CUDA kernel\\
\hline
synchronizeCtx & Pause thread until all CUDA device operations in current context are complete \\
\hline
\end{tabular}
\end{center}
\caption{Main features of \name}
\label{webcudaSpec}
\end{table}

This section describes the \name JavaScript extension. We have modeled our
specification after similar projects \cite{webCL, safariCL, nokiaCL, chromeCL} in
the OpenCL domain.  In addition, the protocols provided by the CUDA Driver API
\cite{cudaAPI} heavily influence the structure and layout of our extension. At a
high level, \name allows a programmer to write the host code managing CUDA
devices in JavaScript. This includes functions for allocating memory,
transferring memory between the host and device, and launching CUDA kernels. As
this is a first step towards enabling web pages to perform GPGPU computing, we
decided that the GPU kernels must still be written in CUDA. This made our
project able to be completed in a semester and also allows users to quickly port
existing CUDA kernels to the \name environment.


Below, we walk through the code example shown in Figure~\ref{codeExample},
highlighting the salient features of \namens. Please refer to
Table~\ref{webcudaSpec} throughout the discussion for a brief summary of 
various \name features. The full \name specification, generated by JSDOC
\cite{JSDOC}, can be found at
\url{http://tshull226.synology.me/CS598SVA/JSDoc/index.html}.


%should only have 1, inclusive code example
%copied off stack exchange as a language format for JavaScript
\lstdefinelanguage{HTML5}{
	sensitive=true,
	keywords={%
		% JavaScript
		typeof, new, true, false, catch, function, return, null, catch,
		switch, var, if, in, while, do, else, case, break,
		% HTML
		html, title, meta, style, head, body, script, canvas,
		% CSS
		border:, transform:, -moz-transform:,
		transition-duration:, transition-property:,
		transition-timing-function:
	},
	% http://texblog.org/tag/otherkeywords/
	otherkeywords={<, >, \/},   
	ndkeywords={class, export, boolean,
	throw, implements, import, this},   
	comment=[l]{//},
	% morecomment=[s][keywordstyle]{<}{>},  
	morecomment=[s]{/*}{*/},
	morecomment=[s]{<!}{>},
	morestring=[b]',
	morestring=[b]",    
	alsoletter={-},
	alsodigit={:}
}
\lstset{ language=HTML5, numbers=left, stepnumber=1, escapeinside={\%}{*)}}
\begin{figure*}
	\begin{center}
		\small
		\lstinputlisting{example.js}
	\end{center}
	\caption{Simple \name Example}
	\label{codeExample}
\end{figure*}

\paragraph{Context Creation} The CUDA Driver API dictates the steps necessary to
connect to a CUDA-enabled device and create an environment for kernel execution.
While the process is similar to native CUDA programming, many items, namely,
context creation, must be done explicitly. A CUDA context is associated with a
specific process thread and is used to differentiate between multiple
threads interacting with a CUDA-enabled device simultaneously.  A simpler, implicit context creation, as is
done in the CUDA Runtime, is left as future work.
%the CUDA drivers are able to associate
%After a context
%is created for a thread,  all memory allocations to a specific device, thus allow different processes to have
%different unshared address spaces. 

Figure~\ref{codeExample}, lines 2-7 shows the protocol for
retrieving a handle to a CUDA-enabled device and creating a CUDA context. Since
a context is associated with a specific CUDA device, a handle to a CUDA-enabled
device must first be attained. Passed along with the handle to the device is a
flag indicating any special features this CUDA context is to have.

\paragraph{Memory Allocation} Memory within the current CUDA context can be
allocated through the \textit{webcuda.memAlloc()} function. Similar to
cuMemAlloc(), this function allocates a linear memory region containing the
number of bytes given as a parameter. Lines 8 and 9 in Figure~\ref{codeExample}
show the creation of device and host memory.  Our specification requires host
memory JavaScript Objects to be Typed Arrays \cite{typedarray} in order to communicate
with device memory. Typed Arrays are a feature of the new ``harmony''
specification \cite{harmony}. Possible Types include Int16, UInt16, Int32, Float32, and many
other variants. While typical JavaScript Arrays can hold arbitrary types of Objects and must be
allocated accordingly, Type Arrays enforce data sizes and therefore can be
allocated the same way as C arrays. This allows for efficient communication
between the host and device.


\paragraph{Data Communication} \name supports two functions,
\textit{webcuda.CopyDtoH()} and \textit{webcuda.CopyHtoD()}, for transferring
data between the host and CUDA-enabled device. Lines 12 and 33 show examples of
copying memory from the host to device and vice versa. As described in the
previous paragraph, Type Arrays, are used to maximize
communication efficiency. Currently, only synchronous memory transfers are
allowed, but subsequent work can implement support for asynchronous memory
accesses.

\paragraph{Kernel Setup} Lines 14-16 show the compilation of a CUDA file and the
extraction of a kernel from the module. The CUDA Driver API specifies that a
CUDA module must first be loaded and the kernel function retrieved from the
module before a kernel can be launched. \name supports three ways of loading a
CUDA module: loading a pre-compiled .ptx or .cubin file, performing on-the-fly
loading and compilation of a .cu file, or performing on-the-fly compilation of a
JavaScript string.  The example on line 14 uses the on-the-fly compilation of a
.cu file. This loaded module is regular CUDA code and can contain many CUDA
kernels.  Therefore, the specific kernel one wants to launch must also be
queried, as shown on line 16. \name supports loading and execution of
multiple CUDA kernels from the multiple sources.

\paragraph{Kernel Execution} Lines 18-28 show the setup and execution of the
CUDA kernel. The grid and block dimensions must be passed to the kernel as
arrays of Integers. Note that in the current implementation of \namens, all
dimensions must explicitly be given a value, unlike the CUDA runtime where
unfilled dimensions are implicitly assigned the value 1. \name has support for
shared memory; the amount needed must be given in byte size. Finally, parameters
are passed to the kernel in an array of objects. Each element in the array must
be an object with a property name describing the type of value being passed.
Allowable property names are \textit{memParam}, \textit{intParam},
\textit{floatParam}, and \textit{doubleParam}. The elements in the array must be
passed in the same order as expected by the CUDA kernel function.

The launching of the CUDA array, performed by \textit{webcuda.launchKernel()}, is
done asynchronously. Therefore, it is recommended to call
\textit{webcuda.synchronizeCtx()} afterward to block the host until all device operations
have completed.

\paragraph{Freeing Resources}
After the CUDA kernel has completed and the results have been transferred to the
host (Line 32), the final step is to free all resources acquired during the
kernel launch. Lines 34-36 show the \name calls to release the memory, module,
and context resources allocated.

%The process shown above should be very similar regardless of the CUDA kernels being
%run. 

We expect the process of launching most kernels to be similar to the steps
described above.  The main differences should be the type of memory used, the
amount of memory used, and the number of kernels executed. We hope by walking
through a simple program and explaining key \name features, one has enough of an
understanding to begin programming in \namens.

